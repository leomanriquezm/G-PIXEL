{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9HaGbPvjaHD"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/instances_images\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVE20EILjcT0",
        "outputId": "a52c1bec-8d6e-4874-dd6c-6509b25460f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Standard library\n",
        "# ================================\n",
        "import os\n",
        "import random\n",
        "\n",
        "# ================================\n",
        "# Array / image handling\n",
        "# ================================\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# ================================\n",
        "# PyTorch\n",
        "# ================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "\n",
        "# ================================\n",
        "# TorchVision (transforms)\n",
        "# ================================\n",
        "from torchvision import transforms\n",
        "\n",
        "# ================================\n",
        "# Scikit-learn\n",
        "# ================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# Visualization\n",
        "# ================================\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "yJj0YvxyjcWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/instances_images\"\n"
      ],
      "metadata": {
        "id": "CfjR6g_UjcYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Semilla -----\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Dispositivo (CPU o GPU si hay)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Transformaciones: redimensionar + tensor + normalización simple\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),   # importante para que coincida con la CNN\n",
        "    transforms.ToTensor()\n",
        "    # Podríamos agregar Normalize si queremos, pero lo dejamos simple por ahora\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GraphImagesDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Guardamos todas las rutas de imagen (png/jpg/jpeg)\n",
        "        valid_exts = (\".png\", \".jpg\", \".jpeg\")\n",
        "        self.image_paths = [\n",
        "            os.path.join(root_dir, f)\n",
        "            for f in os.listdir(root_dir)\n",
        "            if f.lower().endswith(valid_exts)\n",
        "        ]\n",
        "\n",
        "        # Definimos las clases y sus índices\n",
        "        self.class_names = ['barabasi', 'watts', 'erdos']\n",
        "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Sacar el nombre de archivo\n",
        "        filename = os.path.basename(img_path)\n",
        "        prefix = filename.split('_')[0].lower()  # primera palabra\n",
        "\n",
        "        if prefix not in self.class_to_idx:\n",
        "            raise ValueError(f\"Clase desconocida en archivo {filename}: {prefix}\")\n",
        "\n",
        "        label = self.class_to_idx[prefix]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "dataset = GraphImagesDataset(data_path, transform=transform)\n",
        "print(\"Total de imágenes:\", len(dataset))\n",
        "\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_ds, val_ds = random_split(\n",
        "    dataset,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_ds), \"Val:\", len(val_ds))\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Entrada: 3 x 32 x 32\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        # Después de 2 maxpool(2):\n",
        "        # 32x32 -> 16x16 -> 8x8, con 64 canales\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 3)  # 3 clases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)   # 3x32x32 -> 32x16x16\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)   # 32x16x16 -> 64x8x8\n",
        "\n",
        "        x = torch.flatten(x, 1)  # a vector\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)          # logits (sin softmax)\n",
        "        return x\n",
        "\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "\n",
        "def train_loop(n_epochs, model, optimizer, loss_fn, train_loader, device):\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 1. forward\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # 2. backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            total += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        print(f\"Época {epoch}/{n_epochs} - Loss train: {epoch_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\n",
        "n_epochs = 100  # puedes cambiarlo\n",
        "train_loop(n_epochs, model, optimizer, loss_fn, train_loader, device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnFqxCpkjccn",
        "outputId": "edb811f2-45ea-4e01-daa6-04fb5f5895e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes: 1440\n",
            "Train: 1152 Val: 288\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n",
            "Época 1/100 - Loss train: 1.0989\n",
            "Época 2/100 - Loss train: 1.0987\n",
            "Época 3/100 - Loss train: 1.0986\n",
            "Época 4/100 - Loss train: 1.0987\n",
            "Época 5/100 - Loss train: 1.0983\n",
            "Época 6/100 - Loss train: 1.0981\n",
            "Época 7/100 - Loss train: 1.0979\n",
            "Época 8/100 - Loss train: 1.0976\n",
            "Época 9/100 - Loss train: 1.0972\n",
            "Época 10/100 - Loss train: 1.0975\n",
            "Época 11/100 - Loss train: 1.0967\n",
            "Época 12/100 - Loss train: 1.0966\n",
            "Época 13/100 - Loss train: 1.0961\n",
            "Época 14/100 - Loss train: 1.0956\n",
            "Época 15/100 - Loss train: 1.0952\n",
            "Época 16/100 - Loss train: 1.0947\n",
            "Época 17/100 - Loss train: 1.0932\n",
            "Época 18/100 - Loss train: 1.0928\n",
            "Época 19/100 - Loss train: 1.0908\n",
            "Época 20/100 - Loss train: 1.0884\n",
            "Época 21/100 - Loss train: 1.0855\n",
            "Época 22/100 - Loss train: 1.0827\n",
            "Época 23/100 - Loss train: 1.0759\n",
            "Época 24/100 - Loss train: 1.0643\n",
            "Época 25/100 - Loss train: 1.0475\n",
            "Época 26/100 - Loss train: 1.0177\n",
            "Época 27/100 - Loss train: 0.9575\n",
            "Época 28/100 - Loss train: 0.8496\n",
            "Época 29/100 - Loss train: 0.7025\n",
            "Época 30/100 - Loss train: 0.5752\n",
            "Época 31/100 - Loss train: 0.4785\n",
            "Época 32/100 - Loss train: 0.4357\n",
            "Época 33/100 - Loss train: 0.4077\n",
            "Época 34/100 - Loss train: 0.3720\n",
            "Época 35/100 - Loss train: 0.3540\n",
            "Época 36/100 - Loss train: 0.3249\n",
            "Época 37/100 - Loss train: 0.2948\n",
            "Época 38/100 - Loss train: 0.2649\n",
            "Época 39/100 - Loss train: 0.2346\n",
            "Época 40/100 - Loss train: 0.2190\n",
            "Época 41/100 - Loss train: 0.1711\n",
            "Época 42/100 - Loss train: 0.1356\n",
            "Época 43/100 - Loss train: 0.1099\n",
            "Época 44/100 - Loss train: 0.0887\n",
            "Época 45/100 - Loss train: 0.0814\n",
            "Época 46/100 - Loss train: 0.0668\n",
            "Época 47/100 - Loss train: 0.0671\n",
            "Época 48/100 - Loss train: 0.0525\n",
            "Época 49/100 - Loss train: 0.0471\n",
            "Época 50/100 - Loss train: 0.0462\n",
            "Época 51/100 - Loss train: 0.0560\n",
            "Época 52/100 - Loss train: 0.0452\n",
            "Época 53/100 - Loss train: 0.0382\n",
            "Época 54/100 - Loss train: 0.0328\n",
            "Época 55/100 - Loss train: 0.0402\n",
            "Época 56/100 - Loss train: 0.0314\n",
            "Época 57/100 - Loss train: 0.0347\n",
            "Época 58/100 - Loss train: 0.0251\n",
            "Época 59/100 - Loss train: 0.0311\n",
            "Época 60/100 - Loss train: 0.0271\n",
            "Época 61/100 - Loss train: 0.0227\n",
            "Época 62/100 - Loss train: 0.0244\n",
            "Época 63/100 - Loss train: 0.0250\n",
            "Época 64/100 - Loss train: 0.0238\n",
            "Época 65/100 - Loss train: 0.0179\n",
            "Época 66/100 - Loss train: 0.0222\n",
            "Época 67/100 - Loss train: 0.0192\n",
            "Época 68/100 - Loss train: 0.0187\n",
            "Época 69/100 - Loss train: 0.0184\n",
            "Época 70/100 - Loss train: 0.0290\n",
            "Época 71/100 - Loss train: 0.0166\n",
            "Época 72/100 - Loss train: 0.0164\n",
            "Época 73/100 - Loss train: 0.0195\n",
            "Época 74/100 - Loss train: 0.0265\n",
            "Época 75/100 - Loss train: 0.0221\n",
            "Época 76/100 - Loss train: 0.0168\n",
            "Época 77/100 - Loss train: 0.0204\n",
            "Época 78/100 - Loss train: 0.0154\n",
            "Época 79/100 - Loss train: 0.0172\n",
            "Época 80/100 - Loss train: 0.0169\n",
            "Época 81/100 - Loss train: 0.0191\n",
            "Época 82/100 - Loss train: 0.0238\n",
            "Época 83/100 - Loss train: 0.0169\n",
            "Época 84/100 - Loss train: 0.0234\n",
            "Época 85/100 - Loss train: 0.0127\n",
            "Época 86/100 - Loss train: 0.0103\n",
            "Época 87/100 - Loss train: 0.0129\n",
            "Época 88/100 - Loss train: 0.0111\n",
            "Época 89/100 - Loss train: 0.0092\n",
            "Época 90/100 - Loss train: 0.0112\n",
            "Época 91/100 - Loss train: 0.0143\n",
            "Época 92/100 - Loss train: 0.0097\n",
            "Época 93/100 - Loss train: 0.0093\n",
            "Época 94/100 - Loss train: 0.0114\n",
            "Época 95/100 - Loss train: 0.0186\n",
            "Época 96/100 - Loss train: 0.0139\n",
            "Época 97/100 - Loss train: 0.0085\n",
            "Época 98/100 - Loss train: 0.0108\n",
            "Época 99/100 - Loss train: 0.0176\n",
            "Época 100/100 - Loss train: 0.0186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def validate(model, train_loader, val_loader, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "            all_labels = []\n",
        "            all_preds = []\n",
        "\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "                # Guardar resultados para métricas\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Calcular métricas\n",
        "            acc  = accuracy_score(all_labels, all_preds)\n",
        "            prec = precision_score(all_labels, all_preds, average='macro')\n",
        "            rec  = recall_score(all_labels, all_preds, average='macro')\n",
        "            f1   = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "            print(f\"{name.capitalize()} Accuracy : {acc:.4f}\")\n",
        "            print(f\"{name.capitalize()} Precision: {prec:.4f}\")\n",
        "            print(f\"{name.capitalize()} Recall   : {rec:.4f}\")\n",
        "            print(f\"{name.capitalize()} F1-score : {f1:.4f}\")\n",
        "            print(\"-\"*40)\n",
        "\n",
        "# Ejecutar\n",
        "validate(model, train_loader, val_loader, device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UiANa15jco5",
        "outputId": "51a9a6b9-7ed8-4e7d-f622-a0f8400e303b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : 0.9983\n",
            "Train Precision: 0.9983\n",
            "Train Recall   : 0.9983\n",
            "Train F1-score : 0.9983\n",
            "----------------------------------------\n",
            "Val Accuracy : 0.9965\n",
            "Val Precision: 0.9966\n",
            "Val Recall   : 0.9966\n",
            "Val F1-score : 0.9966\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir etiquetas de clase explícitas\n",
        "class_labels = ['BA','ER','WS']\n",
        "\n",
        "def evaluar_con_matriz(model, loader, device, nombre=\"Conjunto\", modelo=\"cnn\"):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Métricas\n",
        "    acc  = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, average='macro')\n",
        "    rec  = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1   = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    print(f\"{nombre} Accuracy : {acc:.4f}\")\n",
        "    print(f\"{nombre} Precision: {prec:.4f}\")\n",
        "    print(f\"{nombre} Recall   : {rec:.4f}\")\n",
        "    print(f\"{nombre} F1-score : {f1:.4f}\")\n",
        "    print(\"-\"*40)\n",
        "\n",
        "    # Matriz de confusión con etiquetas de clase\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                  display_labels=class_labels)\n",
        "    disp.plot(cmap=\"Blues\" if nombre==\"Train\" else \"Oranges\", values_format=\"d\")\n",
        "    plt.title(f\"{nombre}\")\n",
        "\n",
        "    # Guardar gráfico con nombre del modelo y conjunto\n",
        "    filename = f\"{modelo}_{nombre.lower()}_confusion.png\"\n",
        "    plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"Gráfico guardado en: {filename}\")\n",
        "\n",
        "# Ejecutar para train y val\n",
        "evaluar_con_matriz(model, train_loader, device, nombre=\"Train\", modelo=\"cnn\")\n",
        "evaluar_con_matriz(model, val_loader, device, nombre=\"Test\", modelo=\"cnn\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cH8G4bn3jctB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa66839-1e87-45a8-cf5c-7857a55145f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : 0.9983\n",
            "Train Precision: 0.9983\n",
            "Train Recall   : 0.9983\n",
            "Train F1-score : 0.9983\n",
            "----------------------------------------\n",
            "Gráfico guardado en: cnn_train_confusion.png\n",
            "Test Accuracy : 0.9965\n",
            "Test Precision: 0.9966\n",
            "Test Recall   : 0.9966\n",
            "Test F1-score : 0.9966\n",
            "----------------------------------------\n",
            "Gráfico guardado en: cnn_test_confusion.png\n"
          ]
        }
      ]
    }
  ]
}